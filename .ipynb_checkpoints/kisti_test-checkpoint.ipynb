{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from random import seed, random, randrange\n",
    "from math import exp\n",
    "from csv import reader\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler # Preprocessing\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_data = pd.read_csv('all_data2.csv')\n",
    "df_data = np.loadtxt('all_data2.csv', delimiter=',', skiprows=1)\n",
    "print(df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var = 'map_idx'\n",
    "data = pd.concat([df_data['pm2_5'], df_data[var]], axis=1)\n",
    "data.plot.scatter(x=var, y='pm2_5', ylim=(0,4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X, y = df_data.drop([\"pm2_5\"], axis = 1), (df_data[\"pm2_5\"])\n",
    "X = df_data[:, 1:]\n",
    "y = df_data[:,0]\n",
    "print(\"Training set shape (%d,%d)\" %X.shape)\n",
    "#y = y.values.reshape(-1, 1)\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert y to binary class\n",
    "y_ = (y >= 1.5).astype(int)\n",
    "print(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert y to multiple classes\n",
    "print(y)\n",
    "y_ = np.copy(y)\n",
    "y_[np.argwhere(y < 0.5)[:,0]] = 0\n",
    "y_[np.argwhere(np.logical_and(y >= 0.5, y < 1.5))[:,0]] = 1\n",
    "y_[np.argwhere(np.logical_and(y >= 1.5, y < 2.5))[:,0]] = 2\n",
    "y_[np.argwhere(y >= 2.5)[:,0]] = 3\n",
    "print(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Label categorical values\n",
    "cat_features = [0, 0]\n",
    "for feature in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    X[:, feature]  = le.fit_transform(X[:, feature])\n",
    "    print(X[:, feature])\n",
    "    # Perform one hot encoding\n",
    "    ohe = OneHotEncoder(sparse = False)\n",
    "    # Name columns\n",
    "    columns = [str(feature) + '_' + str(class_) for class_ in le.classes_]\n",
    "    #Drop first column to avoid dummy variable trap\n",
    "    X_dummies = ohe.fit_transform(X[:, feature].reshape(-1,1))[:,1:]\n",
    "    print(X_dummies.shape)\n",
    "    # Drop original feature\n",
    "    #X = X.drop(feature, axis=1)\n",
    "    X = np.delete(X, feature, axis=1)\n",
    "    #X = pd.concat([X, X_dummies], axis=1)\n",
    "    X = np.concatenate((X, X_dummies), axis=1)\n",
    "    \n",
    "print(\"\\n After One Hot Encoding\")\n",
    "print(\"Training set shape (%d,%d)\" %X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = X\n",
    "target = y_\n",
    "train_set, validate_set, y_train, y_validate = train_test_split(dataset, target, test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.savetxt('train_set.data', train_set, fmt='%.2f')\n",
    "#np.savetxt('validate_set.data', validate_set, fmt='%.2f')\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = train_set\n",
    "X_validate = validate_set\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(1000, ), max_iter=10, alpha=1e-2, random_state=1, verbose=True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_validate)\n",
    "print(\"accuracy = %f\" %accuracy_score(y_validate, y_predict))\n",
    "print(\"recall = %f\" %recall_score(y_validate, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.count_nonzero(y_validate == 1)\n",
    "print np.count_nonzero(y_predict == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
